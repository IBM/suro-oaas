package com.ibm.au.optim.suro.docloud.job.impl;

import com.ibm.au.optim.suro.docloud.Constants;
import com.ibm.au.optim.suro.docloud.util.CplexLogFileParser;
import com.ibm.au.optim.suro.model.control.job.JobExecutor;
import com.ibm.au.optim.suro.model.entities.RunDetails;
import com.ibm.au.optim.suro.model.entities.RunLogEntry;
import com.ibm.au.optim.suro.model.entities.Run;
import com.ibm.au.optim.suro.model.entities.RunStatus;
import com.ibm.au.jaws.web.core.runtime.Environment;
import com.ibm.optim.oaas.client.OperationException;
import com.ibm.optim.oaas.client.job.JobClient;
import com.ibm.optim.oaas.client.job.JobNotFoundException;
import com.ibm.optim.oaas.client.job.model.JobExecutionStatus;
import com.ibm.optim.oaas.client.job.model.JobLogItem;
import com.ibm.optim.oaas.client.job.model.JobLogRecord;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.List;

/**
 * Monitor used to monitor a resumed job. This is different from the {@link DOCloudJobMonitor} as it is not using a
 * stream to receive updates, but will poll updates in a regular interval, comparing the response with previous
 * responses to figure out the new log items that need to be processed.
 *
 * @author Peter Ilfrich
 */
public class DOCloudResumeJobMonitor extends DOCloudJobMonitor {

    /**
     * A {@link Logger} instance that is used to collect all the log messages
     * generated by instances of this class and route them to the appropriate
     * logging listeners.
     */
    private static final Logger LOGGER = LoggerFactory.getLogger(DOCloudResumeJobMonitor.class);


    /**
     * Interval to commit optimization log updates to DB, in milliseconds
     */
    public static final int UPDATE_INTERVAL = 5000; // 5 second update

    /**
     * Stores how many log items have been retrieved so far. This is used to only poll the newest log messages from
     * DOCloud.
     */
    private long lastUpdateIndex = 0;


    /**
     * Creates a new instance of a resume job monitor.
     * @param env  - the current server environment
     * @param exec - the job executor executing this job
     * @param resumedRunId - the id of the run
     * @param docClient - a configured DOCloud client
     */
    public DOCloudResumeJobMonitor(Environment env, JobExecutor exec, String resumedRunId, JobClient docClient) {
        super(exec, docClient, resumedRunId, env);
    	// initialize inherited properties

        this.jobRunning = true;

       
        // load job ID
        synchronized (this.runRepository) {
            Run run = this.runRepository.getItem(resumedRunId);
            this.jobId = run.getJobId();
        }

        this.runDetails = runDetailsRepository.findByRunId(resumedRunId);
        // if no existing result, create a new one
        if (this.runDetails == null) {
            this.runDetails = new RunDetails();
            this.runDetails.setRunId(runId);
            this.runDetailsRepository.addItem(runDetails);
        }

        this.monitor = logMonitorExecutor.submit(new ResumeLogMonitor());
    }


    /**
     * Triggers the restart of a run. This concludes the functionality of this job monitor.
     */
    private void restartRun() {
        debug("Restarting run.");
        core.restartRun(this.runId);
        finished();
    }

    /**
     * Handles a successful optimisation, retrieving the results and completing the run.
     */
    private void handleSuccess() {
        // load results
        debug("Job finished successful.");
        processed(null);
        completed(null);
        finished();
    }

    /**
     * Handles an interruption of the job, which includes downloading the result at the point when the job was interrupted.
     */
    private void handleInterruption() {
        debug("Handle interruption.");
        interruption(null);
        completed(null);
        finished();
    }

    /**
     * Handles the failure of a job.
     */
    private void handleFailure() {
        debug("Handle failure");
        failed(null);
        finished();
    }

    /**
     * Handle updates: in a regular interval, this method will download any additional job logs that were created since
     * the last check. The new job logs are parsed and passed to the notifier / stored in the run repository.
     */
    private void handleUpdate() {
    	
    	Run run = getRun();
    	
    	
    	
        // if status hasn't been updated, do it now
        if (RunStatus.RESUME == run.getStatus()) {
        	
            synchronized (runRepository) {
                run = getRun();
                runController.setRunStatus(run, RunStatus.PROCESSING);
            }
        }
        
        try {
            List<? extends JobLogItem> logs = jobClient.getJobLogItems(jobId, lastUpdateIndex);
            CplexLogFileParser parser = new CplexLogFileParser(Constants.DOCLOUD_DATE_FORMATTER, this.runId);
            for (JobLogItem log : logs) {
                for (JobLogRecord record : log.getEngineLogRecords()) {
                    // read the message
                    RunLogEntry entry = parser.parseLine(record);
                    if (entry != null) {
                        if (runDetails.addEntry(entry)) {
                            getJobExecutor().notifyOptimEvent(this.runId, entry);
                            commitChanges(false);
                        }
                    }
                }
                // increment the starting position for the next update
                lastUpdateIndex++;
            }
            
        	parser.close();
        	
            
        } catch (Exception e) {
            LOGGER.error("Error occurred while trying to retrieve the job for the current monitor instance.", e);
        } 
    }


    /**
     * Sends a pre-formatted debug message.
     * @param message - the debug message to log
     */
    private void debug(String message) {
        LOGGER.debug("[RESUMEMONITOR] Run: " + runId + " / Job: " + jobId + " > " + message);
    }


    /**
     * Class <b>LogMonitory</b>. This class implements {@link Runnable} and defines
     * real-time job monitor to read optimization log entries from "live" CPLEX log
     * file. New entries are appended and persisted to a DB on a given update interval.
     * New entries are also published to the notification bus for push to listening
     * clients.
     */
    private class ResumeLogMonitor implements Runnable {



        /**
         * Creates an instance of the {@link com.ibm.au.optim.suro.docloud.job.impl.DOCloudResumeJobMonitor.ResumeLogMonitor} class.
         */
        public ResumeLogMonitor() {
        }


        /**
         * This is the main method of the {@link LogMonitor} which is executed in the
         * thread. The method creates an instance of {@link com.ibm.au.optim.suro.docloud.util.CplexLogFileParser} and
         * attaches it to the live log stream configured with the instance of the
         * {@link DOCloudJobMonitor} that contains this class. It then enters a reading
         * loop where each line is processed and if the time interval surpasses the
         * default update interval it pushes to the notification bus the information
         * about parsed {@link com.ibm.au.optim.suro.model.entities.RunLogEntry} instance.
         */
        @Override
        public void run() {
            LOGGER.debug("Log monitor running for job " + jobId);
            while (isJobRunning()) {
                try {
                    // check job status
                    JobExecutionStatus currentStatus = jobClient.getJobExecutionStatus(jobId);

                    // happy path statuses
                    if (currentStatus.equals(JobExecutionStatus.CREATED)) {
                        // job is created and needs to be executed (cleanup job and restart run)
                        restartRun();
                    } else if (currentStatus.equals(JobExecutionStatus.NOT_STARTED)) {
                        // job in queue, awaiting execution - no update
                        // TODO: job should've been restarted
                    } else if (currentStatus.equals(JobExecutionStatus.RUNNING)) {
                        // job is running, fetch updates
                        handleUpdate();
                    } else if (currentStatus.equals(JobExecutionStatus.PROCESSED)) {
                        // job is done, fetch results
                        handleSuccess();
                    } else if (currentStatus.equals(JobExecutionStatus.INTERRUPTING)) {
                        // do nothing, another thread may be active, job will switch status into INTERRUPT soon
                        // TODO: set to RunStatus.ABORTING
                    } else if (currentStatus.equals(JobExecutionStatus.INTERRUPTED)) {
                        // execution interrupted, handle status
                        handleInterruption();
                    } else if (currentStatus.equals(JobExecutionStatus.FAILED)) {
                        // execution failed, handle error and finish run
                        handleFailure();
                    } else {
                        LOGGER.error("Unknown job execution status detected: " + currentStatus.name());
                    }
                } catch (JobNotFoundException noJob) {
                    LOGGER.error("Job no longer exists.", noJob);
                    core.deleteRun(runId);
                    setJobRunning(false);
                } catch (OperationException opEx) {
                    LOGGER.error("Resume job monitor threw an error when trying to access DOCloud", opEx);
                    setJobRunning(false);
                }


                // wait for a bit
                try {
                    Thread.sleep(UPDATE_INTERVAL);
                } catch (InterruptedException ie) {
                    LOGGER.debug("Resume job monitor received an InterruptedException");
                }
            }

            finished();
        }
    }
}
